{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目基于PP-YOLOE-SOD实现了基于无人机影像的小目标车辆检测，并比较了大尺度和切图两种涨点方案，具体结果如下：\n",
    "\n",
    "\n",
    "| 模型名称 | IoU=0.50:0.95 | FPS |\n",
    "| -------- | -------- | -------- |\n",
    "| ppyoloe_plus_sod_crn_l_80e_coco     | 0.643     | 17.378     |\n",
    "| ppyoloe_plus_sod_crn_l_largesize_80e_visdrone     | 0.633     | 4.899     |\n",
    "| ppyoloe_plus_sod_crn_l_80e_coco     | 0.710     | 23.057     |\n",
    "\n",
    "切图后模型在子图上验证约有6.7%的精度提升，并提供了一种模型量化的方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、项目背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无人机的使用始于21世纪初的军事目的，但随着时间的推移，它们已开始用于其他领域。交通管理中最具挑战性的问题之一是复杂的场景，例如在交通环形路口和交叉路口。在这些复杂的场景中，无人机可用于与自动驾驶汽车或交通基础设施相结合，为它们提供没有这种空中视野就无法获得的信息。\n",
    "\n",
    "智能交通领域的其他工作包括RGB热图像的语义分割以及突出物体的识别。在这些任务中，传统的RGB图像与热图像以及深度图像相结合，以利用所有可用的环境信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个从无人机 （UAV） 获取的西班牙道路交通图像数据集，旨在用于训练深度学习模型以提高道路交通视觉和管理系统的性能。\n",
    "\n",
    "数据集由 15070 张 png 格式的图像组成，并附有对应txt格式的标注文件。这些图像在城市道路的六个不同位置拍摄，标记有155328辆汽车，包括汽车（137602辆）和摩托车（17726辆）。\n",
    "\n",
    "| Scenes | Sequences | Frames | Targets | Cars | Motorbikes |\n",
    "| -------- | -------- | -------- | -------- | -------- | -------- |\n",
    "| Regional road | sec1 | 4,500 | 24,858 | 14,577 | 10,281 |\n",
    "| Urban intersection | sec9, seca, secb, secc | 2,462 | 10,759 | 10,759 | 0 |\n",
    "| Rural road | sec7 | 1,292 | 746 | 746 | 0 |\n",
    "| Split roundabout | sec8 | 3,107 | 3,107 | 3,107 | 0 |\n",
    "| Roundabout (far) | sec2, sec3 | 1,814 | 71,819 | 64,844 | 6,975 |\n",
    "| Roundabout (near) | sec4, sec5, sec6 | 3,997 | 44,039 | 43,569 | 470 |\n",
    "| Total |  | 15,070 | 155,328 | 137,602 | 17,726 |\n",
    "\n",
    "标注文件包含以下内容：\n",
    "* Object class：介于 0 和 N-1 之间的整数。本数据集包含两个类别：0.Cars，1.Motorcycles。\n",
    "* x， y：相对于包含标记对象的矩形中心的十进制值。它们的范围为 [0.0 到 1.0]。\n",
    "* Weight、Height：相对于包含标记对象的矩形的宽度和高度的十进制值。它们的范围为 [0.0 到 1.0]。\n",
    "\n",
    "部分数据如下所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/bbe888be2fa34eecb3e7fcfcf610f73f02ceed2bcef04fe382da1509f8849ff5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step01：** 解压数据集到/home/aistudio/work目录下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip /home/aistudio/data/data203056/archive.zip -d /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step02：** 分隔开图片和标注文件。\n",
    "\n",
    "工作目录：/home/aistudio/work。\n",
    "* Vehicle：处理后的数据集的存放位置。\n",
    "* JPEGImages：Vehicle目录下的子文件夹，用于存放数据集中的图片。\n",
    "* txt_label：Vehicle目录下的子文件夹，用于存放数据集中的原有的txt格式的标注文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/work/\n",
    "!mkdir Vehicle\n",
    "%cd Vehicle\n",
    "!mkdir JPEGImages\n",
    "!mkdir txt_label\n",
    "!mv /home/aistudio/work/dataset/sec1/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec1/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec2/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec2/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec3/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec3/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec4/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec4/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec5/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec5/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec6/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec6/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec7/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec7/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec8/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec8/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/sec9/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/sec9/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/seca/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/seca/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/secb/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/secb/*.txt /home/aistudio/work/Vehicle/txt_label/\n",
    "!mv /home/aistudio/work/dataset/secc/*.png /home/aistudio/work/Vehicle/JPEGImages/\n",
    "!mv /home/aistudio/work/dataset/secc/*.txt /home/aistudio/work/Vehicle/txt_label/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step03：** 将txt格式标注文件转换成可供训练的xml格式标注文件。\n",
    "\n",
    "* Annotations：Vehicle目录下的子文件夹，用于存放转换后的xml格式的标注文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xml.dom.minidom import Document\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    " \n",
    "\n",
    "def makexml(picPath, txtPath, xmlPath):  \n",
    "    # 标签映射\n",
    "    dic = {'0': \"Cars\", '1': \"Motorcycles\"}\n",
    "    files = os.listdir(txtPath)\n",
    "    for i, name in enumerate(files):\n",
    "        if not os.path.getsize(txtPath + name):\n",
    "             print(name, \" is empty!\")\n",
    "             shutil.move(txtPath + name, \"/home/aistudio/work/Vehicle/EmptyTxt/\" + name) \n",
    "             shutil.move(picPath + name[0:-4] + \".png\", \"/home/aistudio/work/Vehicle/UnLabeled/\" + name[0:-4] + \".png\") \n",
    "             continue\n",
    "        if name == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        xmlBuilder = Document()\n",
    "        annotation = xmlBuilder.createElement(\"annotation\")  # 创建annotation标签\n",
    "        xmlBuilder.appendChild(annotation)\n",
    "        txtFile = open(txtPath + name)\n",
    "        txtList = txtFile.readlines()\n",
    "        img = cv2.imread(picPath + name[0:-4] + \".png\")      # .jpg/.png\n",
    "        Pheight, Pwidth, Pdepth = img.shape\n",
    " \n",
    "        folder = xmlBuilder.createElement(\"folder\")  # folder标签\n",
    "        foldercontent = xmlBuilder.createTextNode(\"datasetRGB\")\n",
    "        folder.appendChild(foldercontent)\n",
    "        annotation.appendChild(folder) \n",
    " \n",
    "        filename = xmlBuilder.createElement(\"filename\")  # filename标签\n",
    "        filenamecontent = xmlBuilder.createTextNode(name[0:-4] + \".jpg\")\n",
    "        filename.appendChild(filenamecontent)\n",
    "        annotation.appendChild(filename) \n",
    " \n",
    "        size = xmlBuilder.createElement(\"size\")  # size标签\n",
    "        width = xmlBuilder.createElement(\"width\")  # size子标签width\n",
    "        widthcontent = xmlBuilder.createTextNode(str(Pwidth))\n",
    "        width.appendChild(widthcontent)\n",
    "        size.appendChild(width) \n",
    " \n",
    "        height = xmlBuilder.createElement(\"height\")  # size子标签height\n",
    "        heightcontent = xmlBuilder.createTextNode(str(Pheight))\n",
    "        height.appendChild(heightcontent)\n",
    "        size.appendChild(height) \n",
    " \n",
    "        depth = xmlBuilder.createElement(\"depth\")  # size子标签depth\n",
    "        depthcontent = xmlBuilder.createTextNode(str(Pdepth))\n",
    "        depth.appendChild(depthcontent)\n",
    "        size.appendChild(depth) \n",
    " \n",
    "        annotation.appendChild(size) \n",
    " \n",
    "        for j in txtList:\n",
    "            oneline = j.strip().split(\" \")\n",
    "            object = xmlBuilder.createElement(\"object\")  # object 标签\n",
    "            picname = xmlBuilder.createElement(\"name\")  # name标签\n",
    "            namecontent = xmlBuilder.createTextNode(dic[oneline[0]])\n",
    "            picname.appendChild(namecontent)\n",
    "            object.appendChild(picname) \n",
    " \n",
    "            pose = xmlBuilder.createElement(\"pose\")  # pose标签\n",
    "            posecontent = xmlBuilder.createTextNode(\"Unspecified\")\n",
    "            pose.appendChild(posecontent)\n",
    "            object.appendChild(pose) \n",
    " \n",
    "            truncated = xmlBuilder.createElement(\"truncated\")  # truncated标签\n",
    "            truncatedContent = xmlBuilder.createTextNode(\"0\")\n",
    "            truncated.appendChild(truncatedContent)\n",
    "            object.appendChild(truncated) \n",
    " \n",
    "            difficult = xmlBuilder.createElement(\"difficult\")  # difficult标签\n",
    "            difficultcontent = xmlBuilder.createTextNode(\"0\")\n",
    "            difficult.appendChild(difficultcontent)\n",
    "            object.appendChild(difficult) \n",
    " \n",
    "            bndbox = xmlBuilder.createElement(\"bndbox\")  # bndbox标签\n",
    "            xmin = xmlBuilder.createElement(\"xmin\")  # xmin标签\n",
    "            mathData = int(((float(oneline[1])) * Pwidth + 1) - (float(oneline[3])) * 0.5 * Pwidth)\n",
    "            xminContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            xmin.appendChild(xminContent)\n",
    "            bndbox.appendChild(xmin) \n",
    " \n",
    "            ymin = xmlBuilder.createElement(\"ymin\")  # ymin标签\n",
    "            mathData = int(((float(oneline[2])) * Pheight + 1) - (float(oneline[4])) * 0.5 * Pheight)\n",
    "            yminContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            ymin.appendChild(yminContent)\n",
    "            bndbox.appendChild(ymin) \n",
    " \n",
    "            xmax = xmlBuilder.createElement(\"xmax\")  # xmax标签\n",
    "            mathData = int(((float(oneline[1])) * Pwidth + 1) + (float(oneline[3])) * 0.5 * Pwidth)\n",
    "            xmaxContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            xmax.appendChild(xmaxContent)\n",
    "            bndbox.appendChild(xmax) \n",
    " \n",
    "            ymax = xmlBuilder.createElement(\"ymax\")  # ymax标签\n",
    "            mathData = int(((float(oneline[2])) * Pheight + 1) + (float(oneline[4])) * 0.5 * Pheight)\n",
    "            ymaxContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            ymax.appendChild(ymaxContent)\n",
    "            bndbox.appendChild(ymax)  \n",
    " \n",
    "            object.appendChild(bndbox)  # bndbox标签结束\n",
    " \n",
    "            annotation.appendChild(object) \n",
    " \n",
    "        f = open(xmlPath + name[0:-4] + \".xml\", 'w')\n",
    "        print(name)\n",
    "        xmlBuilder.writexml(f, indent='\\t', newl='\\n', addindent='\\t', encoding='utf-8')\n",
    "        f.close()\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    picPath = \"/home/aistudio/work/Vehicle/JPEGImages/\"  # 图片所在文件夹路径\n",
    "    txtPath = \"/home/aistudio/work/Vehicle/txt_label/\"  # txt所在文件夹路径\n",
    "    xmlPath = \"/home/aistudio/work/Vehicle/Annotations/\"  # xml文件保存路径\n",
    "    makexml(picPath, txtPath, xmlPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码块用于可视化xml格式标注文件中的标注结果，以判断是否准确无误。\n",
    "\n",
    "由于数据集过大，不建议可视化全部的图片，可视化部分文件即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "src_XML_dir = '/home/aistudio/work/Vehicle/Annotations'  # xml源路径\n",
    "src_IMG_dir = '/home/aistudio/work/Vehicle/JPEGImages'  # IMG原路径\n",
    "IMG_format = '.png'    # IMG格式\n",
    "out_dir = '/home/aistudio/work/output'  # 输出路径\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "xml_file = os.listdir(src_XML_dir)  # 只返回文件名称,带后缀\n",
    "\n",
    "for each_XML in xml_file:  # 遍历所有xml文件\n",
    "    # 读入IMG\n",
    "    if each_XML == \".ipynb_checkpoints\":\n",
    "        continue\n",
    "    xml_FirstName = os.path.splitext(each_XML)[0]\n",
    "    img_save_file = os.path.join(out_dir, xml_FirstName+IMG_format)\n",
    "    img_src_path = os.path.join(src_IMG_dir, xml_FirstName+IMG_format)\n",
    "    img = cv2.imread(img_src_path)\n",
    "    # 解析XML\n",
    "    each_XML_fullPath = src_XML_dir + '/' + each_XML  # 每个xml文件的完整路径\n",
    "    tree = ET.parse(each_XML_fullPath)  # ET.parse()内要为完整相对路径\n",
    "    root = tree.getroot()  # 类型为element\n",
    "\n",
    "    # 画框\n",
    "    for obj in root.findall('object'):\n",
    "        if obj.find('bndbox'):\n",
    "            if obj.find('name').text == 'Cars':\n",
    "                bndbox = obj.find('bndbox')\n",
    "                xmin = int(bndbox.find('xmin').text)\n",
    "                xmax = int(bndbox.find('xmax').text)\n",
    "                ymin = int(bndbox.find('ymin').text)\n",
    "                ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "                cv2.rectangle(img=img,\n",
    "                            pt1=(xmin,ymin),\n",
    "                            pt2=(xmax,ymax),\n",
    "                            color=(0,0,255),\n",
    "                            thickness=2)\n",
    "\n",
    "            if obj.find('name').text == ' Motorcycles':\n",
    "                bndbox = obj.find('bndbox')\n",
    "                xmin = int(bndbox.find('xmin').text)\n",
    "                xmax = int(bndbox.find('xmax').text)\n",
    "                ymin = int(bndbox.find('ymin').text)\n",
    "                ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "                cv2.rectangle(img=img,\n",
    "                            pt1=(xmin,ymin),\n",
    "                            pt2=(xmax,ymax),\n",
    "                            color=(0,255,0),\n",
    "                            thickness=2)\n",
    "\n",
    "    cv2.imwrite(filename=img_save_file, img=img)\n",
    "    print('保存结果{}'.format(xml_FirstName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step04：** 单独存放空标注的图片和标注文件。\n",
    "\n",
    "在上一步中发现存在部分未标注的图片，由于PaddleDetection暂不支持负样本训练，因此我们需要在这一步中将未标注图片和对应的标注文件(此处虽然有对应的标注文件，但不存在有效的标注信息)单独取出。\n",
    "\n",
    "* EmptyTxt：Vehicle目录下的子文件夹，用于未标注图片对应的标注文件。\n",
    "* UnLabeled：Vehicle目录下的子文件夹，用于未标注的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir EmptyTxt\n",
    "!mkdir UnLabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "XmlDir = r\"/home/aistudio/work/Vehicle/Annotations\"\n",
    "JpgDir = r\"/home/aistudio/work/Vehicle/JPEGImages\"\n",
    "\n",
    "NoXml = []\n",
    "NoJpg = []\n",
    "\n",
    "for root, dirs, files in os.walk(JpgDir):\n",
    "    for file in files:\n",
    "        if file == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        if file[-1] == 'g':\n",
    "            if os.path.exists(XmlDir + \"/\"+file[:-3] + \"xml\") is False:\n",
    "                NoXml.append(JpgDir+\"/\"+file)\n",
    "\n",
    "for root, dirs, files in os.walk(XmlDir):\n",
    "    for file in files:\n",
    "        if file == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        if file[-1] == 'l':\n",
    "            if os.path.exists(JpgDir + \"/\"+file[:-3] + \"png\") is False:\n",
    "                NoJpg.append(XmlDir+\"/\"+file)\n",
    "if len(NoXml) == 0:\n",
    "    print(\"All jpg are labeled\")\n",
    "else:\n",
    "    print(\"%d unlabeled\" % len(NoXml))\n",
    "    print(NoXml)\n",
    "    for xml in NoXml:\n",
    "        os.remove(xml)\n",
    "\n",
    "if len(NoJpg) == 0:\n",
    "    print(\"All xml have a jpg\")\n",
    "else:\n",
    "    print(\"%d xmls have no jpg\" % len(NoJpg))\n",
    "    print(NoJpg)\n",
    "    for jpg in NoJpg:\n",
    "        os.remove(jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step05：** 划分数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先安装PaddleX。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install paddlex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过split_dataset这个API按照0.75：0.15：0.1的比例划分训练集、验证集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!paddlex --split_dataset --format VOC --dataset_dir /home/aistudio/work/Vehicle --val_value 0.15 --test_value 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step06：** 将VOC格式数据集转换成COCO格式数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，安装PaddleDetection。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 克隆PaddleDetection仓库\n",
    "%cd /home/aistudio/\n",
    "#!git clone https://github.com/PaddlePaddle/PaddleDetection.git\n",
    "\n",
    "# 安装其他依赖\n",
    "%cd PaddleDetection\n",
    "!pip install -r requirements.txt --user\n",
    "\n",
    "# 编译安装paddledet\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，将数据集移动到/home/aistudio/PaddleDetection/dataset目录下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:16:50.441668Z",
     "iopub.status.busy": "2023-03-28T02:16:50.440808Z",
     "iopub.status.idle": "2023-03-28T02:16:50.662168Z",
     "shell.execute_reply": "2023-03-28T02:16:50.661194Z",
     "shell.execute_reply.started": "2023-03-28T02:16:50.441636Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mv /home/aistudio/work/Vehicle /home/aistudio/PaddleDetection/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，通过运行tools/x2coco.py将VOC格式数据集转换成COCO格式数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tools/x2coco.py将VOC格式数据集转换成COCO格式数据集的时候，总是将png后缀的图片写入成jpg格式。经查找，并未找到对应的配置参数进行修改。因此，我决定从源码入手进行如下修改：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7e86d6f3481c4d2daef82c9175ce6ed364733647c0384efcb4b42df50a975243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/x2coco.py \\\n",
    "        --dataset_type voc \\\n",
    "        --voc_anno_dir dataset/Vehicle/ \\\n",
    "        --voc_anno_list dataset/Vehicle/train_list.txt \\\n",
    "        --voc_label_list dataset/Vehicle/labels.txt \\\n",
    "        --voc_out_name dataset/Vehicle/voc_train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/x2coco.py \\\n",
    "        --dataset_type voc \\\n",
    "        --voc_anno_dir dataset/Vehicle/ \\\n",
    "        --voc_anno_list dataset/Vehicle/val_list.txt \\\n",
    "        --voc_label_list dataset/Vehicle/labels.txt \\\n",
    "        --voc_out_name dataset/Vehicle/voc_val.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/x2coco.py \\\n",
    "        --dataset_type voc \\\n",
    "        --voc_anno_dir dataset/Vehicle/ \\\n",
    "        --voc_anno_list dataset/Vehicle/test_list.txt \\\n",
    "        --voc_label_list dataset/Vehicle/labels.txt \\\n",
    "        --voc_out_name dataset/Vehicle/voc_test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、数据集分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行该代码块，我们可以看到：\n",
    "* 图片尺寸分为两种：[1080,1920]和[720,1280]；\n",
    "* 训练集共有2793张图片，包含29005个标注物体；\n",
    "* 标签类别为2，Cars/Motorcycles;\n",
    "* Cars：MotoCycles = 88.7%：11.3%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "myfont = FontProperties(fname=r\"/home/aistudio/work/times.ttf\", size=12)\n",
    "plt.rcParams['figure.figsize'] = (12, 12)\n",
    "plt.rcParams['font.family']= myfont.get_family()\n",
    "plt.rcParams['font.sans-serif'] = myfont.get_name()\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def generate_anno_eda(dataset_path, anno_file):\n",
    "    with open(os.path.join(dataset_path, anno_file)) as f:\n",
    "        anno = json.load(f)\n",
    "    print('标签类别:', anno['categories'])\n",
    "    print('类别数量：', len(anno['categories']))\n",
    "    print('训练集图片数量：', len(anno['images']))\n",
    "    print('训练集标签数量：', len(anno['annotations']))\n",
    "    \n",
    "    total=[]\n",
    "    for img in anno['images']:\n",
    "        hw = (img['height'],img['width'])\n",
    "        total.append(hw)\n",
    "    unique = set(total)\n",
    "    for k in unique:\n",
    "        print('长宽为(%d,%d)的图片数量为：'%k,total.count(k))\n",
    "    \n",
    "    ids=[]\n",
    "    images_id=[]\n",
    "    for i in anno['annotations']:\n",
    "        ids.append(i['id'])\n",
    "        images_id.append(i['image_id'])\n",
    "    print('训练集图片数量:', len(anno['images']))\n",
    "    print('unique id 数量：', len(set(ids)))\n",
    "    print('unique image_id 数量', len(set(images_id)))\n",
    "    \n",
    "    # 创建类别标签字典\n",
    "    category_dic=dict([(i['id'],i['name']) for i in anno['categories']])\n",
    "    counts_label=dict([(i['name'],0) for i in anno['categories']])\n",
    "    for i in anno['annotations']:\n",
    "        counts_label[category_dic[i['category_id']]] += 1\n",
    "    label_list = counts_label.keys()    # 各部分标签\n",
    "    print('标签列表:', label_list)\n",
    "    size = counts_label.values()    # 各部分大小\n",
    "    color = ['#FFB6C1', '#D8BFD8']     # 各部分颜色\n",
    "    # explode = [0.05, 0, 0]   # 各部分突出值\n",
    "    patches, l_text, p_text = plt.pie(size, labels=label_list, colors=color, labeldistance=1.1, autopct=\"%1.1f%%\", shadow=False, startangle=90, pctdistance=0.6, textprops={'fontproperties':myfont})\n",
    "    plt.axis(\"equal\")    # 设置横轴和纵轴大小相等，这样饼才是圆的\n",
    "    plt.legend(prop=myfont)\n",
    "    plt.show()\n",
    "\n",
    "# 分析训练集数据\n",
    "generate_anno_eda('/home/aistudio/PaddleDetection/dataset/Vehicle', 'voc_train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过运行tools/box_distribution.py我们可以统计数据集分布。\n",
    "* Suggested reg_range[1] is # DFL算法中推荐值，在 PP-YOLOE-SOD 模型的配置文件的head中设置为此值，效果最佳\n",
    "* Mean of all img_w is 1644.3394199785178 # 原图宽的平均值\n",
    "* Mean of all img_h is 924.9409237379163 # 原图高的平均值\n",
    "* Median of ratio_w is 0.040345982142857145 # 标注框的宽与原图宽的比例的中位数\n",
    "* Median of ratio_h is 0.044444444444444446 # 标注框的高与原图高的比例的中位数\n",
    "* all_img with box:  2793 # 数据集图片总数(排除无框或空标注的图片)\n",
    "* all_ann:  29005 # 数据集标注框总数\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d3d0480f6d294ab39764c0999a567a375eecf3027a1e4a8bb5b9217aa8d506c7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/box_distribution.py --json_path dataset/Vehicle/voc_train.json --out_img box_distribution.jpg --eval_size 640 --small_stride 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本项目中我选择的PP-YOLOE-SOD系列模型。\n",
    "\n",
    "PaddleDetection团队提供了针对VisDrone-DET、DOTA水平框、Xview等小目标场景数据集的基于PP-YOLOE改进的检测模型 PP-YOLOE-SOD，以及提供了一套使用SAHI(Slicing Aided Hyper Inference)工具的切图和拼图的方案。\n",
    "\n",
    "PP-YOLOE-SOD 是PaddleDetection团队自研的小目标检测特色模型，使用数据集分布相关的基于向量的DFL算法 和 针对小目标优化的中心先验优化策略，并且在模型的Neck(FPN)结构中加入Transformer模块，以及结合增加P2层、使用large size等策略，最终在多个小目标数据集上达到极高的精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在运行过程中我们可能会遇到以下问题：\n",
    "```\n",
    "Error: /paddle/paddle/phi/kernels/gpu/one_hot_kernel.cu:38 Assertion `p_in_data[idx] >= 0 && p_in_data[idx] < depth` failed. Illegal index value, Input(input) value should be greater than or equal to 0, and less than depth [70644], but received [94393729526616].\n",
    "```\n",
    "解决方案：学习率lr调低10倍，具体可以参考[PPYOLOE：又快又好的小目标检测训练与部署实现](https://aistudio.baidu.com/aistudio/projectdetail/4435291)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py -c configs/smalldet/ppyoloe_plus_sod_crn_l_80e_coco.yml --amp --eval --use_vdl True --vdl_log_dir vdl_log_dir/ppyoloe_plus_sod_crn_l_80e_coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数如图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6cfc2a15b6c64aefbb818f2bef558f9e6add0e2269ff4c5383fd7639e8826494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/eval.py -c configs/smalldet/ppyoloe_plus_sod_crn_l_80e_coco.yml -o weights=output/ppyoloe_plus_sod_crn_l_80e_coco/best_model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的各项指标如下所示：\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
    "* Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.953\n",
    "* Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.744\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.564\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.732\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.646\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.787\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.822\n",
    "* Total sample number: 558, average FPS: 17.377526192569604\n",
    "\n",
    "我们可以对上述指标进行一定的定量分析：\n",
    "* IoU=0.50意味着IoU大于0.5被认为是检测到，即将IoU设为0.5时，计算每一类的所有图片的AP，然后所有类别求平均，即mAP。\n",
    "* IoU=0.50:0.95意味着IoU在0.5到0.95的范围内被认为是检测到，表示在不同IoU阈值（从0.50到0.95，步长0.05）（0.5、0.55、0.6、0.65、0.7、0.75、0.8、0.85、0.9、0.95）上的平均mAP。\n",
    "* 越低的IoU阈值，则判为正确检测的越多，相应的，Average Precision (AP)也就越高。\n",
    "* small表示标注的框面积小于32 * 32；\n",
    "* medium表示标注的框面积同时小于96 * 96；\n",
    "* large表示标注的框面积大于等于96 * 96；\n",
    "* all表示不论大小，我都要。\n",
    "* maxDets=100表示最大检测目标数为100。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 涨点方案！大尺度VS切图！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 大尺度训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们输入模型的尺寸是[1080,1920]和[720,1280]，而模型的输入尺寸是[640,640]。将数据输入模型的时候不可避免地会损失一定的细节信息，同时本项目又存在大量的小目标检测物体，因此会导致模型精度的下降。我们很自然地首先就想到可以使用大尺度进行训练。\n",
    "\n",
    "本项目是基于1600尺度为基础的多尺度训练，将训练的batch_size减小，以速度来换取高精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python tools/train.py -c configs/smalldet/visdrone/ppyoloe_plus_sod_crn_l_largesize_80e_visdrone.yml --amp --eval --use_vdl True --vdl_log_dir vdl_log_dir/ppyoloe_plus_sod_crn_l_largesize_80e_visdrone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数如图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/caeac4643d16445aa910d33013b185940f23d0d645044acfb98effa786eaa743)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/eval.py -c configs/smalldet/visdrone/ppyoloe_plus_sod_crn_l_largesize_80e_visdrone.yml -o weights=output/ppyoloe_plus_sod_crn_l_largesize_80e_visdrone/best_model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的各项指标如下所示：\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633\n",
    "* Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.973\n",
    "* Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.734\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.568\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.658\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.766\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770\n",
    "* Total sample number: 558, average FPS: 4.898954086318949\n",
    "\n",
    "我们可以看到，大尺度训练在该任务中并未达到很好的涨点效果，精度下降了1%，同时速度也发生了大幅度的下降。感兴趣的小伙伴可以自行调参看是否能够达到更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 切图训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对超大分辨率的数据集，我们还有一种方法就是使用切图后的子图训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step01：** 安装SAHI和必要的依赖库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sahi\n",
    "!pip install -U scikit-image imagecodecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step02：** 基于SAHI切图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PP-YOLOE-SOD现支持的切图尺寸有三种：\n",
    "\n",
    "| 模型 | 数据集 | SLICE_SIZE | OVERLAP_RATIO |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| PP-YOLOE-P2-l     | DOTA     | 500     | 0.25     |\n",
    "| PP-YOLOE-P2-l     | Xview     | 400     | 0.25     |\n",
    "| PP-YOLOE-l     | VisDrone-DET     | 640     | 0.25     |\n",
    "\n",
    "在上文我们提到，本项目数据集的尺寸是[1080,1920]和[720,1280]，本身尺寸并没有特别的大，所以我决定以500为基础进行切图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/slice_image.py --image_dir dataset/Vehicle/JPEGImages --json_path dataset/Vehicle/voc_train.json --output_dir dataset/Vehicle_sliced --slice_size 500 --overlap_ratio 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/slice_image.py --image_dir dataset/Vehicle/JPEGImages --json_path dataset/Vehicle/voc_val.json --output_dir dataset/Vehicle_sliced --slice_size 500 --overlap_ratio 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step03：** 训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练过程中我们可能会遇到如下问题：\n",
    "```\n",
    "ValueError: (InvalidArgument) The 2-th dimension of input[0] and input[1] is expected to be equal.But received input[0]'s shape = [1, 192, 64, 64], input[1]'s shape = [1, 256, 63, 63].\n",
    "  [Hint: Expected inputs_dims[0][j] == inputs_dims[i][j], but received inputs_dims[0][j]:64 != inputs_dims[i][j]:63.] (at /paddle/paddle/phi/kernels/funcs/concat_funcs.h:83)\n",
    "```\n",
    "解决方案：需要我们注意的是，虽然我们切图后的子图尺寸是500，但500不是32的倍数，不能直接输入模型进行训练，所以我们训练的尺寸可以设置为512。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时切图后可能会存在大量的负样本，但这不影响我们后续的训练。\n",
    "```\n",
    "ppdet.data.source.coco INFO: Load [17215 samples valid, 16259 samples invalid] in file dataset/Vehicle_sliced/voc_train_500_025.json.\n",
    "ppdet.data.source.coco INFO: Load [3511 samples valid, 3319 samples invalid] in file dataset/Vehicle_sliced/voc_val_500_025.json.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py -c configs/smalldet/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025.yml --amp --eval --use_vdl True --vdl_log_dir vdl_log_dir/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数如图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b9743783fe5d4badbf35a25154f55701b10c5ff15e354ed7bcca41c0ecfc8389)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python tools/eval.py -c configs/smalldet/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025.yml -o weights=output/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025/best_model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
    "* Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
    "* Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.830\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.644\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.776\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.796\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.710\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.764\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.712\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.827\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827\n",
    "* Total sample number: 3511, average FPS: 23.05708607036652\n",
    "\n",
    "在切分的子图上，模型约能涨点6.7%，速度提升5.68。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/eval.py -c configs/smalldet/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025_infer.yml -o weights=output/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025/best_model.pdparams --slice_infer --combine_method=nms --match_threshold=0.6 --match_metric=ios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估模型的时候，我们可以选择子图拼图评估，这样更接近实际的检测效果。\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
    "* Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.955\n",
    "* Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.737\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.615\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.681\n",
    "* Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.716\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.690\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.751\n",
    "* Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
    "* Total sample number: 558, average FPS: 0.6696922658566277\n",
    "\n",
    "我们可以看到，切图训练精度损失约0.2%，但不可避免地推理速度发生了大幅度的下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step03：** 预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以预测部分图片，观察一下模型的实际检测效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/infer.py -c configs/smalldet/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025.yml -o weights=output/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025/best_model.pdparams --infer_img=dataset/Vehicle/JPEGImages/sec7_frame_000943.png --draw_threshold=0.5 --slice_infer --slice_size 500 500 --overlap_ratio 0.25 0.25 --combine_method=nms --match_threshold=0.6 --match_metric=ios --save_results=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分可视化结果如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5bd4a3476c8a419aacca37c3a085e8b93232a70b01424cfbaaed43418714a4cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 模型导出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我将以ppyoloe_plus_sod_crn_l_80e_coco模型为例介绍OpenVINO-Python部署方案，因此首先需要先导出相应的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/export_model.py -c configs/smalldet/ppyoloe_plus_sod_crn_l_80e_coco.yml -o weights=output/ppyoloe_plus_sod_crn_l_80e_coco/best_model.pdparams\r\n",
    "!python tools/export_model.py -c configs/smalldet/visdrone/ppyoloe_plus_sod_crn_l_largesize_80e_visdrone.yml -o weights=output/ppyoloe_plus_sod_crn_l_largesize_80e_visdrone/best_model.pdparams\r\n",
    "!python tools/export_model.py -c configs/smalldet/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025.yml -o weights=output/ppyoloe_p2_crn_l_80e_sliced_DOTA_500_025/best_model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 模型压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们需要安装PaddleSlim。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install paddleslim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目选择的是在线量化的方式。一般量化训练直接在训好的浮点模型上进行finetune少量Epoch即可，finetune过程中，学习率也需要适当调小。量化训练的优点是在训练中调整权重分布以适应模拟量化计算，从而大幅降低量化模型的精度损失，一般优于离线量化方法。缺点是训练过程较慢，资源要求较高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/train.py -c configs/smalldet/ppyoloe_plus_sod_crn_l_80e_coco.yml --slim_config configs/slim/quant/ppyoloe_plus_sod_crn_l_80e_coco_qat.yml -r output/ppyoloe_plus_sod_crn_l_80e_coco_qat/14.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码块导出训练好的量化模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/export_model.py -c configs/smalldet/ppyoloe_plus_sod_crn_l_80e_coco.yml --slim_config configs/slim/quant/ppyoloe_plus_sod_crn_l_80e_coco_qat.yml -o weights=output/ppyoloe_plus_sod_crn_l_80e_coco_qat/model_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算模型推理时延前需要安装部分依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install GPUtil --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于统计整个测试集图片的时间过长，我决定取出一百张图片进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "img_name = [] \n",
    "def create_test_dir(img_dir):\n",
    "    count = 0\n",
    "    for filename in os.listdir(img_dir):\n",
    "        if count==100:\n",
    "            break\n",
    "        count = count + 1\n",
    "        img = cv2.imread(img_dir + \"/\" + filename)\n",
    "        cv2.imwrite(\"/home/aistudio/PaddleDetection/dataset/Vehicle/benchmark/\"+filename, img)\n",
    "        img_name.append(img)\n",
    "        print(filename)\n",
    "\n",
    "create_test_dir(\"/home/aistudio/PaddleDetection/dataset/Vehicle/JPEGImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python deploy/python/infer.py --model_dir=output_inference/ppyoloe_plus_sod_crn_l_80e_coco --image_dir=dataset/Vehicle/benchmark --device=GPU --run_benchmark True --run_mode paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cpu_rss(MB): 3162, cpu_vms: 0, cpu_shared_mb: 0, cpu_dirty_mb: 0, cpu_util: 0%\n",
    "* gpu_rss(MB): 1641, gpu_util: 0.14%, gpu_mem_util: 0%\n",
    "* total time spent(s): 8.6659\n",
    "* preprocess_time(ms): 45.5, inference_time(ms): 41.2, postprocess_time(ms): 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python deploy/python/infer.py --model_dir=output_inference/ppyoloe_plus_sod_crn_l_80e_coco_qat --image_dir=dataset/Vehicle/benchmark --device=GPU --run_benchmark True --run_mode trt_int8 --run_mode False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cpu_rss(MB): 3461, cpu_vms: 0, cpu_shared_mb: 0, cpu_dirty_mb: 0, cpu_util: 0%\n",
    "* gpu_rss(MB): 1647, gpu_util: 0.12%, gpu_mem_util: 0%\n",
    "* total time spent(s): 8.0766\n",
    "* preprocess_time(ms): 47.9, inference_time(ms): 32.8, postprocess_time(ms): 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在线量化后模型的推理速度提升了20%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、OpenVINO-Python部署方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenVINO runtime api的调用流程如图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/cbd7900e046043339ff66d64fd8102020d6cf6a4548c4343aebb553f4db92042)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目现已基于此流程将模型在本地部署实现。\n",
    "\n",
    "项目部署环境：\n",
    "* 笔记本型号：R9000P\n",
    "* 操作系统：Windows10\n",
    "* Cuda版本：11.6\n",
    "* OpenVINO版本：2022.3\n",
    "* 编译器环境：Pycharm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create OpenVINO Runtime Core：\n",
    "```\n",
    "ie_core = Core()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compile Model：\n",
    "```\n",
    "det_model = ie_core.read_model(model=\"ppyoloe_plus_sod_crn_l_80e_coco/model.pdmodel\")\n",
    "det_model.reshape({'image': [1, 3, 640, 640], 'scale_factor': [1, 2]})\n",
    "detector = ie_core.compile_model(model=det_model, device_name=\"CPU\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 & 4. Create Inference Request & Set Inputs：\n",
    "```\n",
    "image = cv2.imread(\"sec3_frame_000700.png\")\n",
    "scale_factor = np.array([[1, 2]]).astype('float32')  # 超参数\n",
    "img = cv2.resize(image, (640, 640))  # 尺寸缩放\n",
    "img = np.transpose(img, [2, 0, 1]) / 255  # 归一化\n",
    "img = np.expand_dims(img, 0)  # 拓展维度(C, H, W) -> (1, C, H, W)\n",
    "img_mean = np.array([0.0, 0.0, 0.0]).reshape((3, 1, 1))\n",
    "img_std = np.array([1.0, 1.0, 1.0]).reshape((3, 1, 1))\n",
    "img -= img_mean\n",
    "img /= img_std\n",
    "inputs_dict = {'image': img, \"scale_factor\": scale_factor}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Start Inference：\n",
    "```\n",
    "output_layer = detector.output(0)\n",
    "results = detector(inputs_dict)[output_layer]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Process Inference Result：\n",
    "```\n",
    "score_threshold = 0.5  # 输出阈值\n",
    "filtered_results = []\n",
    "for i in range(len(results)):\n",
    "    if results[i, 1] > score_threshold:\n",
    "        filtered_results.append(results[i])\n",
    "det_image = det_visualization(image, filtered_results)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化结果如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e9fda85c2f1f42559effa581ad96bee277b191e90c244d7d97c8f764c055fc67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时我已经将该推理部署文件上传至/home/aistudio/work目录下，大家可以自行查看！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、总结提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目基于PP-YOLOE-SOD实现了基于无人机影像的小目标车辆检测，并比较了大尺度和切图两种涨点方案，具体结果如下：\n",
    "\n",
    "\n",
    "| 模型名称 | IoU=0.50:0.95 | FPS |\n",
    "| -------- | -------- | -------- |\n",
    "| ppyoloe_plus_sod_crn_l_80e_coco     | 0.643     | 17.378     |\n",
    "| ppyoloe_plus_sod_crn_l_largesize_80e_visdrone     | 0.633     | 4.899     |\n",
    "| ppyoloe_plus_sod_crn_l_80e_coco     | 0.710     | 23.057     |\n",
    "\n",
    "切图后模型在子图上验证约有6.7%的精度提升。\n",
    "\n",
    "后续工作：\n",
    "* 后期会在OpenVINO上实现C++环境下的模型部署。\n",
    "* 进一步压缩模型达到更好的落地效果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
